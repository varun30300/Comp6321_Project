{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7171753,"sourceType":"datasetVersion","datasetId":4143713},{"sourceId":7171761,"sourceType":"datasetVersion","datasetId":4143719}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom torchvision.datasets import ImageFolder\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom sklearn.metrics import accuracy_score\nfrom itertools import product\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier \n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T00:53:37.952280Z","iopub.status.idle":"2023-12-11T00:53:37.952630Z","shell.execute_reply.started":"2023-12-11T00:53:37.952461Z","shell.execute_reply":"2023-12-11T00:53:37.952477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n\nfrom PIL import Image\nclasses= ['MUS','NORM', 'STR']\n# Load the trained model\nmodel_path = '/kaggle/input/savedmodel/model_final.pth'  # Update this path\nmodel = resnet18(pretrained=False)  # Use the same model architecture as you used for training\nmodel.fc = nn.Linear(model.fc.in_features, len(classes))  # Adjust the fully connected layer as per your model\n# Load the state dictionary from the file\nstate_dict = torch.load(model_path)\n\n# Filter out unnecessary keys\nfiltered_state_dict = {k: v for k, v in state_dict.items() if 'total_ops' not in k and 'total_params' not in k}\n\n# Load the filtered state dictionary into the model\nmodel.load_state_dict(filtered_state_dict, strict=False)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nmodel.eval()\n\n# Load and preprocess the sample image\ndef preprocess_image(image_path):\n    # Define the transformations. Adjust as per your requirement.\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Example size, adjust to match training\n        transforms.ToTensor(),\n        # Add any other transformations you used during training (e.g., normalization)\n    ])\n\n    # Load image\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image).unsqueeze(0)  # Add batch dimension\n    return image\n\n# Example image path\nsample_image_path = '/kaggle/input/images/colon_cancer_GettyImages1214015886_Header.webp'  # Update this path\nsample_tensor = preprocess_image(sample_image_path).to(device)\n\n# Forward pass to get the prediction\nwith torch.no_grad():\n    output = model(sample_tensor)\n    probabilities = torch.nn.functional.softmax(output, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1)\n\n# Get the class name from the predicted class index\npredicted_class_name = classes[predicted_class.item()]\nprint(f'Predicted Class: {predicted_class_name}')\nprint(f'Class Probabilities: {probabilities}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T00:56:16.455217Z","iopub.execute_input":"2023-12-11T00:56:16.455510Z","iopub.status.idle":"2023-12-11T00:56:29.097584Z","shell.execute_reply.started":"2023-12-11T00:56:16.455485Z","shell.execute_reply":"2023-12-11T00:56:29.096559Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Predicted Class: NORM\nClass Probabilities: tensor([[3.0336e-29, 1.0000e+00, 7.8893e-43]], device='cuda:0')\n","output_type":"stream"}]}]}