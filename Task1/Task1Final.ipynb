{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ZnEZ6aX_9Z"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/MajorAssignmentData/Dataset 1.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1MwYkfmZjXw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import mobilenet_v2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VK9YEf3UUnAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2905c55b-20b9-4405-f2c1-3c270304099e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6ag14OgeTS6"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNjtjGt8cNN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcKqSBnrZocD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "data_dir = '/content/Dataset 1/Colorectal Cancer '\n",
        "\n",
        "\n",
        "classes = ['MUS', 'NORM', 'STR']\n",
        "\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    for filename in os.listdir(class_path):\n",
        "        if filename.endswith('.tif'):\n",
        "            image_path = os.path.join(class_path, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "            images.append(image)\n",
        "            labels.append(class_name)\n",
        "\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVa875mQgVZY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J39XxKkvgiRx"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# Define data transformations\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Ensure input is a PIL image\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Apply transformations to your data\n",
        "X_train_transformed = torch.stack([data_transform(x) for x in X_train])\n",
        "X_val_transformed = torch.stack([data_transform(x) for x in X_val])\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "train_dataset = TensorDataset(X_train_transformed, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_transformed, y_val_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjv3z-8rdiOW",
        "outputId": "f427c60c-4141-4408-c74a-1840710e36df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.5848494052886963, Validation Accuracy: 0.7483333333333333\n",
            "Epoch 2/10, Loss: 0.3610184720158577, Validation Accuracy: 0.6466666666666666\n",
            "Epoch 3/10, Loss: 0.2848620306700468, Validation Accuracy: 0.7083333333333334\n",
            "Epoch 4/10, Loss: 0.23549387770394484, Validation Accuracy: 0.715\n",
            "Epoch 5/10, Loss: 0.19064868637671073, Validation Accuracy: 0.6533333333333333\n",
            "Epoch 6/10, Loss: 0.1906558569148183, Validation Accuracy: 0.7583333333333333\n",
            "Epoch 7/10, Loss: 0.14599895712609093, Validation Accuracy: 0.87\n",
            "Epoch 8/10, Loss: 0.1510388885997236, Validation Accuracy: 0.5816666666666667\n",
            "Epoch 9/10, Loss: 0.12946304828549424, Validation Accuracy: 0.7483333333333333\n",
            "Epoch 10/10, Loss: 0.11464312985228996, Validation Accuracy: 0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Define MobileNetV2 model\n",
        "model = mobilenet_v2(pretrained=False, num_classes=len(classes))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_predictions = []\n",
        "    val_true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            val_predictions.extend(predicted.numpy())\n",
        "            val_true_labels.extend(labels.numpy())\n",
        "\n",
        "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Save the trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "# Define data transformations\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Ensure input is a PIL image\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Apply transformations to your data\n",
        "X_train_transformed = torch.stack([data_transform(x) for x in X_train])\n",
        "X_val_transformed = torch.stack([data_transform(x) for x in X_val])\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "train_dataset = TensorDataset(X_train_transformed, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_transformed, y_val_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define ResNet-18 model with pre-trained weights\n",
        "model = resnet18(pretrained=True)\n",
        "# Modify the final fully connected layer for the number of classes in your dataset\n",
        "model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_predictions = []\n",
        "    val_true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            val_predictions.extend(predicted.numpy())\n",
        "            val_true_labels.extend(labels.numpy())\n",
        "\n",
        "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), '/content/trained_resnet18.pth')\n"
      ],
      "metadata": {
        "id": "MPbnzbIeqN4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5b66a6-04ce-4eca-e1ee-2b5d52c84a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 93.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.2480997323182722, Validation Accuracy: 0.7516666666666667\n",
            "Epoch 2/10, Loss: 0.11646742386432986, Validation Accuracy: 0.66\n",
            "Epoch 3/10, Loss: 0.09539381618766735, Validation Accuracy: 0.7633333333333333\n",
            "Epoch 4/10, Loss: 0.08707807161612437, Validation Accuracy: 0.915\n",
            "Epoch 5/10, Loss: 0.061380552371653414, Validation Accuracy: 0.99\n",
            "Epoch 6/10, Loss: 0.06140756510392142, Validation Accuracy: 0.8983333333333333\n",
            "Epoch 7/10, Loss: 0.025333555562732122, Validation Accuracy: 0.9816666666666667\n",
            "Epoch 8/10, Loss: 0.07151410000020406, Validation Accuracy: 0.9666666666666667\n",
            "Epoch 9/10, Loss: 0.04084833827374192, Validation Accuracy: 0.9133333333333333\n",
            "Epoch 10/10, Loss: 0.023079741673718672, Validation Accuracy: 0.98\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}