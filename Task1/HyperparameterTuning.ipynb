{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aZWXpbf0Eph",
   "metadata": {
    "id": "7aZWXpbf0Eph"
   },
   "source": [
    "# Welcome to Colab Enterprise <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "\n",
    "Connect to a Runtime and begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35856bf2-aa5e-436b-977a-9e5725b1a595",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35856bf2-aa5e-436b-977a-9e5725b1a595",
    "outputId": "d1d6d150-5bf0-4a55-dca5-2cb49c3eef29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate=0.001, batch size=16, epochs=5\n",
      "Epoch 1/5, Loss: 0.563397299721837, Validation Accuracy: 0.6333333333333333\n",
      "Epoch 2/5, Loss: 0.4080287310977777, Validation Accuracy: 0.605\n",
      "Epoch 3/5, Loss: 0.30784684627006453, Validation Accuracy: 0.85\n",
      "Epoch 4/5, Loss: 0.2983188282574217, Validation Accuracy: 0.6883333333333334\n",
      "Epoch 5/5, Loss: 0.2462856774404645, Validation Accuracy: 0.835\n",
      "\n",
      "Training with learning rate=0.001, batch size=16, epochs=10\n",
      "Epoch 1/10, Loss: 0.5862876942257086, Validation Accuracy: 0.57\n",
      "Epoch 2/10, Loss: 0.42840079627931116, Validation Accuracy: 0.7066666666666667\n",
      "Epoch 3/10, Loss: 0.338975270713369, Validation Accuracy: 0.6033333333333334\n",
      "Epoch 4/10, Loss: 0.28906801430508494, Validation Accuracy: 0.6783333333333333\n",
      "Epoch 5/10, Loss: 0.2685334566918512, Validation Accuracy: 0.8933333333333333\n",
      "Epoch 6/10, Loss: 0.20051357930526137, Validation Accuracy: 0.9316666666666666\n",
      "Epoch 7/10, Loss: 0.19404546643917758, Validation Accuracy: 0.44166666666666665\n",
      "Epoch 8/10, Loss: 0.17580738007711869, Validation Accuracy: 0.7983333333333333\n",
      "Epoch 9/10, Loss: 0.16068438554182649, Validation Accuracy: 0.6466666666666666\n",
      "Epoch 10/10, Loss: 0.13557709293595205, Validation Accuracy: 0.42333333333333334\n",
      "\n",
      "Training with learning rate=0.001, batch size=16, epochs=15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "data_dir = '/content/Dataset 1/Colorectal Cancer '\n",
    "\n",
    "classes = ['MUS', 'NORM', 'STR']\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith('.tif'):\n",
    "            image_path = os.path.join(class_path, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "            images.append(image)\n",
    "            labels.append(class_name)\n",
    "\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Ensure input is a PIL image\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameters = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [5, 10, 15]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for lr, bs, ep in itertools.product(hyperparameters['learning_rate'], hyperparameters['batch_size'], hyperparameters['epochs']):\n",
    "    print(f\"\\nTraining with learning rate={lr}, batch size={bs}, epochs={ep}\")\n",
    "\n",
    "    # Convert data to PyTorch tensors for each iteration\n",
    "    X_train_transformed = torch.stack([data_transform(x) for x in X_train])\n",
    "    X_val_transformed = torch.stack([data_transform(x) for x in X_val])\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_transformed, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_transformed, y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "    # Create a new model for each iteration\n",
    "    model = resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(ep):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_true_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predicted.numpy())\n",
    "                val_true_labels.extend(labels.numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "        print(f\"Epoch {epoch + 1}/{ep}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Update the best hyperparameters if needed\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_hyperparameters = {'learning_rate': lr, 'batch_size': bs, 'epochs': ep}\n",
    "\n",
    "# Print the best hyperparameters and validation accuracy\n",
    "print(\"\\nBest Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Validation Accuracy:\", best_val_accuracy)\n",
    "\n",
    "# Save the model with the best hyperparameters\n",
    "best_model = resnet18(weights=None)\n",
    "best_model.fc = nn.Linear(best_model.fc.in_features, len(classes))\n",
    "best_optimizer = optim.Adam(best_model.parameters(), lr=best_hyperparameters['learning_rate'])\n",
    "best_model.load_state_dict(torch.load('/content/trained_resnet18.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "torch.save(best_model.state_dict(), '/content/best_trained_resnet18.pth')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
